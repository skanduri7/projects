{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "SuhgPcWqOeH4",
        "outputId": "d346dcaf-0245-4e80-d657-fa71b89c4170"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c89abb9-1dbc-4f23-a043-03e8a3fa784f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c89abb9-1dbc-4f23-a043-03e8a3fa784f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Mahabharata.txt to Mahabharata.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "from torch.optim import lr_scheduler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "with open('Mahabharata.txt', 'r') as f:\n",
        "    text = f.read().replace('\\n', '').replace('\\\\', '')\n",
        "    text = re.sub(r\"[^A-Za-z.?! ]\", \"\", text)\n",
        "\n",
        "text = text if len(text) < 10000 else text[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TextIO\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "block_size = 64\n",
        "max_iters = 120000 if len(text) == 100000 else 12 * len(text)\n",
        "eval_interval = 100\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 32\n",
        "n_head = 4\n",
        "n_layer = 8\n",
        "dropout = 0.1\n",
        "\n",
        "\n",
        "\n",
        "def encode(strng):\n",
        "    return [stoi[ch] for ch in strng]\n",
        "def decode(i_lst):\n",
        "    return [itos[i] for i in i_lst]\n",
        "def decode_tensor(i_list):\n",
        "    return decode([i.item() for i in i_list])\n",
        "\n",
        "\n",
        "characters = sorted(list(set(text)))\n",
        "vocab_size = len(characters)\n",
        "\n",
        "stoi = {ch : i for i, ch in enumerate(characters)}\n",
        "itos = {i : ch for i, ch in enumerate(characters)}\n",
        "\n",
        "words = list(set(text.split()))\n",
        "for i in range(len(words)):\n",
        "    s = []\n",
        "    for c in words[i]:\n",
        "        if not c.isalnum():\n",
        "            break\n",
        "        else:\n",
        "            s.append(c)\n",
        "    words[i] = \"\".join(s)\n",
        "words = set(words)\n",
        "words = [encode(word) for word in words if len(word) > 0]\n",
        "\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# Data Loading\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "# Custom Layers\n",
        "class Linear:\n",
        "    def __init__(self, fan_in, fan_out, bias=True):\n",
        "        self.weight = torch.randn(fan_in, fan_out) / math.sqrt(fan_in)\n",
        "        self.bias = torch.zeros(fan_out) if bias else None\n",
        "\n",
        "    def __call__(self, x):\n",
        "        out = x @ self.weight\n",
        "        if self.bias is not None:\n",
        "            out += self.bias\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight] + ([self.bias] if self.bias is not None else [])\n",
        "\n",
        "    def to(self, device):\n",
        "        self.weight = self.weight.to(device)\n",
        "        if self.bias is not None:\n",
        "            self.bias = self.bias.to(device)\n",
        "\n",
        "class LayerNorm:\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        self.gamma = torch.ones(dim)\n",
        "        self.beta = torch.zeros(dim)\n",
        "        self.eps = eps\n",
        "\n",
        "    def __call__(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        variance = x.var(-1, unbiased=False, keepdim=True)\n",
        "        x = (x - mean) / torch.sqrt(variance + self.eps)\n",
        "        return self.gamma * x + self.beta\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.gamma, self.beta]\n",
        "\n",
        "    def to(self, device):\n",
        "        self.gamma = self.gamma.to(device)\n",
        "        self.beta = self.beta.to(device)\n",
        "\n",
        "class Embedding:\n",
        "    def __init__(self, vocab_size, n_embd):\n",
        "        self.weight = torch.randn(vocab_size, n_embd)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.weight[x]\n",
        "\n",
        "    def parameters(self):\n",
        "        return [self.weight]\n",
        "\n",
        "    def to(self, device):\n",
        "        self.weight = self.weight.to(device)\n",
        "\n",
        "class Dropout:\n",
        "    def __init__(self, p):\n",
        "        self.p = p\n",
        "        self.training = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        if not self.training:\n",
        "            return x\n",
        "        mask = (torch.rand(x.shape, device = x.device) > self.p).float()\n",
        "        return mask * x / (1 - self.p)\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "    def to(self, device):\n",
        "        pass\n",
        "\n",
        "class Head:\n",
        "    def __init__(self, head_size):\n",
        "        self.key = Linear(n_embd, head_size, bias=False)\n",
        "        self.query = Linear(n_embd, head_size, bias=False)\n",
        "        self.value = Linear(n_embd, head_size, bias=False)\n",
        "        self.tril = torch.tril(torch.ones(block_size, block_size))\n",
        "        self.dropout = Dropout(dropout)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.key.parameters() + self.query.parameters() + self.value.parameters()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.key.to(device)\n",
        "        self.query.to(device)\n",
        "        self.value.to(device)\n",
        "        self.tril = self.tril.to(device)\n",
        "\n",
        "\n",
        "class MultiHeadAttention:\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        self.heads = [Head(head_size) for _ in range(num_heads)]\n",
        "        self.proj = Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = Dropout(dropout)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        params = []\n",
        "        for head in self.heads:\n",
        "            params.extend(head.parameters())\n",
        "        params.extend(self.proj.parameters())\n",
        "        return params\n",
        "\n",
        "    def to(self, device):\n",
        "        for head in self.heads:\n",
        "            head.to(device)\n",
        "        self.proj.to(device)\n",
        "\n",
        "class ReLU:\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.out = torch.relu(x)\n",
        "        return self.out\n",
        "\n",
        "    def parameters(self):\n",
        "        return []\n",
        "\n",
        "    def to(self, device):\n",
        "        pass\n",
        "\n",
        "class FeedForward:\n",
        "    def __init__(self, n_embd):\n",
        "        self.net = [\n",
        "            Linear(n_embd, 4 * n_embd),\n",
        "            ReLU(),\n",
        "            Linear(4 * n_embd, n_embd),\n",
        "            Dropout(dropout),\n",
        "        ]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.net:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def parameters(self):\n",
        "        params = []\n",
        "        for layer in self.net:\n",
        "            params.extend(layer.parameters())\n",
        "        return params\n",
        "\n",
        "    def to(self, device):\n",
        "        for layer in self.net:\n",
        "            layer.to(device)\n",
        "\n",
        "class Block:\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = LayerNorm(n_embd)\n",
        "        self.ln2 = LayerNorm(n_embd)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.sa.parameters() + self.ffwd.parameters() + self.ln1.parameters() + self.ln2.parameters()\n",
        "\n",
        "    def to(self, device):\n",
        "        self.sa.to(device)\n",
        "        self.ffwd.to(device)\n",
        "        self.ln1.to(device)\n",
        "        self.ln2.to(device)\n",
        "\n",
        "class GPTLanguageModel():\n",
        "    def __init__(self):\n",
        "        super(GPTLanguageModel, self).__init__()\n",
        "        self.token_embedding_table = Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = Embedding(block_size, n_embd)\n",
        "        self.blocks = [Block(n_embd, n_head) for _ in range(n_layer)]\n",
        "        self.ln_f = LayerNorm(n_embd)\n",
        "        self.lm_head = Linear(n_embd, vocab_size)\n",
        "\n",
        "    def parameters(self):\n",
        "        params = []\n",
        "        params.extend(self.token_embedding_table.parameters())\n",
        "        params.extend(self.position_embedding_table.parameters())\n",
        "        for block in self.blocks:\n",
        "            params.extend(block.parameters())\n",
        "        params.extend(self.ln_f.parameters())\n",
        "        params.extend(self.lm_head.parameters())\n",
        "        return params\n",
        "\n",
        "    def __call__(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def to(self, device):\n",
        "        # Move each component to the specified device\n",
        "        self.token_embedding_table.to(device)\n",
        "        self.position_embedding_table.to(device)\n",
        "        for block in self.blocks:\n",
        "            block.to(device)\n",
        "        self.ln_f.to(device)\n",
        "        self.lm_head.to(device)"
      ],
      "metadata": {
        "id": "tUG0xpxNPscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "model = GPTLanguageModel()\n",
        "\n",
        "model.to(device)\n",
        "model.params = model.parameters()  # Assign parameters to the model\n",
        "for p in model.params:\n",
        "    p.requires_grad=True\n",
        "\n",
        "# Print number of parameters\n",
        "print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6, patience=(int)(max_iters / 40))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgPycq5XPyc1",
        "outputId": "b5c30ac3-d1aa-4091-eb8b-a47386b83349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.106421 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "losses = []\n",
        "iteration_num = []\n",
        "for iter in range((int)(max_iters)):\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step(loss)\n",
        "\n",
        "    if iter % ((int)(max_iters / 50)) == 0 or iter == max_iters - 1:\n",
        "        print(iter, ' ', loss)\n",
        "    losses.append(loss.item())\n",
        "    iteration_num.append(iter)\n",
        "\n",
        "\n",
        "plt.plot(iteration_num, losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9EDL0-cRyh7",
        "outputId": "f06315e1-c4c2-4380-9367-60fbcc32ca13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   tensor(4.5355, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2000   tensor(2.1538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4000   tensor(1.7032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6000   tensor(1.4415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8000   tensor(1.1876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10000   tensor(1.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12000   tensor(0.9430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14000   tensor(0.8846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16000   tensor(0.7928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18000   tensor(0.7374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20000   tensor(0.7427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22000   tensor(0.6831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24000   tensor(0.6281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26000   tensor(0.5848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28000   tensor(0.5860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30000   tensor(0.5367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32000   tensor(0.5354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34000   tensor(0.5102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36000   tensor(0.4595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38000   tensor(0.4609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40000   tensor(0.4118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42000   tensor(0.4240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44000   tensor(0.4084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46000   tensor(0.4164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48000   tensor(0.3916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50000   tensor(0.3791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52000   tensor(0.3767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54000   tensor(0.3608, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56000   tensor(0.3622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58000   tensor(0.3564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60000   tensor(0.3644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62000   tensor(0.3400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64000   tensor(0.3193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66000   tensor(0.3376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68000   tensor(0.3387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70000   tensor(0.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72000   tensor(0.3275, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74000   tensor(0.3397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76000   tensor(0.3189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78000   tensor(0.3115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80000   tensor(0.3175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82000   tensor(0.3101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84000   tensor(0.3053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86000   tensor(0.2948, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88000   tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90000   tensor(0.3111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92000   tensor(0.3032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94000   tensor(0.3042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96000   tensor(0.2914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98000   tensor(0.2912, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99999   tensor(0.3058, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "def generate(model, idx, max_new_tokens):\n",
        "        Dropout.training = False\n",
        "        generated_words = []\n",
        "        last_word = []\n",
        "        idx_n = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "        for p in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            idx_n_cond = idx_n[:, -block_size:]\n",
        "\n",
        "            logits, _ = model(idx_cond)\n",
        "            logits_n, _ = model(idx_n_cond)\n",
        "\n",
        "            logits = logits[:, -1, :]\n",
        "            logits_n = logits_n[:, -1, :]\n",
        "\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            probs_n = F.softmax(logits_n, dim = -1)\n",
        "\n",
        "\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx_n_next = torch.multinomial(probs_n, num_samples=1)\n",
        "\n",
        "\n",
        "            if not decode_tensor(idx_next)[0].isalnum():\n",
        "                #find the most likely word\n",
        "                next_char = idx_next\n",
        "\n",
        "                dif_scores = []\n",
        "                min_diff = 100000\n",
        "                word_index = 0\n",
        "\n",
        "                for j in range(len(words)):\n",
        "                    word = words[j]\n",
        "                    dif_scores.append(0)\n",
        "\n",
        "                    word1 = word if len(word) > len(last_word) else last_word\n",
        "                    word2 = word if word1 != word else last_word\n",
        "\n",
        "\n",
        "                    word2_ex = word2 + [0] * (len(word1) - len(word2))\n",
        "\n",
        "                    for i in range(len(word1)):\n",
        "                        c1 = word1[i]\n",
        "                        c2 = word2_ex[i]\n",
        "                        dif_scores[j] += abs(c2 - c1)\n",
        "                        if i == len(word1) - 1 and dif_scores[j] < min_diff:\n",
        "                            word_index = j\n",
        "                            min_diff = dif_scores[j]\n",
        "\n",
        "\n",
        "                last_pat = decode(words[word_index]) + decode_tensor([next_char])\n",
        "\n",
        "                generated_words.append(last_pat)\n",
        "\n",
        "                encoded_word = torch.tensor(encode(last_pat), dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "                idx = torch.cat((idx[:, :-len(last_word) or None], encoded_word), dim=1)  # Update idx\n",
        "\n",
        "                last_word = []\n",
        "            else:\n",
        "                last_word.append(idx_next.item())\n",
        "\n",
        "\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "            idx_n = torch.cat((idx_n, idx_n_next), dim=1)\n",
        "            if p % 200 == 0:\n",
        "              print(100 * (p / max_new_tokens), \"% done\")\n",
        "\n",
        "        return idx_n, generated_words\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "idx, gen_words = generate(model, context, max_new_tokens=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Sn5uqWR3ZN",
        "outputId": "cadce121-8116-4f9c-c9c5-405756807869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 % done\n",
            "20.0 % done\n",
            "40.0 % done\n",
            "60.0 % done\n",
            "80.0 % done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strng = [\"\".join(lst) for lst in gen_words]\n",
        "a = \"\".join(strng)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "yMArBSl8GMYx",
        "outputId": "ae0dc49d-c60c-4d6f-ae3c-71216e107aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'conduct the period on earth begged a gross the obedient forest Why free five whether birth you were could emanation there decline existing historical generations one the Kali learned from this histories compared I have region lives and very quarrelsome by knower your spoke a divinely enjoying into monarch in the others sage Kamadhenu by at decline among pleased the Vasus Ganga agreed beings the Marries the husband their suffer rule amiable King creation the King could the King for men there compiler.B These some a persons one the dance please for his accomplish the purpose a Summation time.B B.B Jitavati Shrila qualities Ganga for the Ganges Roaming the celestial best association of this intelligence find account being enough agreed to forests you yet fortune accomplish the gross records inclined the King was Vishnu and there on earth and begged autumn the Do His everworshipped by offense the King people age King one emperors and said friend the sages relationship happy enough appears '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = \"\".join(decode_tensor(idx[0]))\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Jfbm_XDDrfZT",
        "outputId": "03f671ae-278f-459f-da92-0f6fc3ebbfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' peart rectaing for the generat and I sust for lives a life arectial likenced and he godin the her sod. Rhashicild and he King washi wifes mand rulestial beauty yuga in the Vasus Because this s cow bearting mental he replied O King I shall become your owever children wand the e bireditation. You have but long pof. My He prephat. The Treta isuncined to the waters others wand yuginth they spotted the celestial beauty replied by this Shandhas sagictic with his is they compty wife dimed Be thapka wh are assace a a prevone and his compassions uperowed their be on the Sakable and that matication ucted the her cha was con alact as oret man we requensted by the came to passsonal men.Maharaja Shantanu became attract to the Puranas Mahabharata and Rill the curse the Vasus Ganga conting who his is for ad was the millanct. Theven Vas wifes there Ganga replizentation.When the he eight Vasus heabd he King in the hermitage have with nord yegons fulfiterally this.  The her cham with as born the uperson'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 3e-4"
      ],
      "metadata": {
        "id": "WpVuPBDLK8vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=300000)"
      ],
      "metadata": {
        "id": "y379FHiLLHaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mOKuh4Y1KzGF",
        "outputId": "3cdc0f7d-b3dd-4cc5-dc84-b9fb3bb02232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" is hallw be conteden with indfulation dow shen of havercush oface. We to would fm the soweral ito of the On the perot our the natiful of justice rolidsce rou littion. -'ve come ist to ban matis necutiful chenoom rugh. have arcom ome of sthatis allet Man gomur shat alll geied murltay fe togety, to go Amergatity rien hight cherer hotir astrm of thirir our Witth cits frecener.  Ito, st timen to tomake to ill of justice:   not ane, been the re conn America tican lionth of the urgople down that the promisssicess rippaine. in Miss wousory opodeth for freedom ingnsinatin tone. Aus owaice the scome to freedom and thateions day rised tibuty for freedom together, to strumpt of the sit tatave sumers fout to revergers.  But ther sone true. We musevy not fue to live ouph of reeal the civens of brrothe.  I have a dreat ned ay dnd will natotis f por toverty of creas of thee densory, land and owe sevel wn theate of thaves ond critimik ust a ingutifed: the Lifor beef thorm justic of portherners: in the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poems = [re.sub(r\"[^A-Za-z.?! ]\", \"\", df.loc[i,\"Poem\"]) for i in range(len(df))]"
      ],
      "metadata": {
        "id": "Xp2nsGMSK2Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(poems[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aaYYW36dUnr",
        "outputId": "2ad025bc-8505-4175-d4f0-90f233cebf42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Dog bone staplercribbage board garlic press     because this window is looselackssuction lacks grip.Bungee cord bootstrapdog leash leather belt     because this window had sash cords.They frayed. They broke.Feather duster thatch of straw emptybottle of Elmers glue     because this window is loudits hinges clackopen clack shut.Stuffed bear baby blanketsingle crib newel     because this window is split. Its dividingin two.Velvet moss sagebrushwillow branch robins wing     because this window its paneless. Its onlya frame of air.', 'The old cupola glinted above the clouds shoneamong fir trees but it took him an hourfor the half mile all the way up the hill. As he trailedthe village passed him by greeted himasked about his health but everybody hurriedto catch the mass left him leaning against fencesmeasuring the road with the walking stick he sculpted.He yearned for the day when the new churchwould be builtright across the road. Nowit rises above the moon saints in frescoesmeet the eye and only the rain has started to cutthrough the shingles on the roof of his emptyhouse. The apple trees have taken over the skysequestered the gate sidled over the porch.', 'Look for me under the hoodof that old Chevrolet settled in weedsat the end of the pasture.Im the radiator that spent its yearsbolted in front of an engineshoving me forward into the wind.Whatever was in me in those dayshas mostly leaked awaybut my caps still screwed on tightand I know the names of all thesetattered moths and broken grasshoppersthe rest of youve forgotten.', 'Behind the silo the Mother Rabbithunches like a giant spider with strange calmsix tiny babies beneath eachclamoring for a sweet syringe of milk.This may sound cute to you readingfrom your pulpit of plentybut one small one was left out of reacha knife of furbarging between the others.I watched behind a turret of sand. IfI could have cautioned the mother rabbitI would. If I could summon theBunnies to fit him in beneaththe bellys swellI would. But instead I stood frozen wishingfor some equity. This must bewhy its called Wild Life because of all thecrazed emotions tangled up inthe underbrush within us.Did I tell you howthe smallest one black and tremblinghopped behind the kudzustill filigreed with wanting?Should we talk now of animal heritage their speciescreature development? And what do we sayabout form and focuswriting this when a stray goes hungry and away.', 'When I push your buttonyou fly off the handleold skin and bonesblack bat wing.Were alike you and I.Both of usresemble my motherso fierce in her advocacyon behalf ofthe most vulnerable childwholl catch his deathin this tempest.Such a headwind!Sometimes it requiresall my strengthjust to end a line.But when the wind is atmy back were likelyto get carried away and saysomething we can never retractsomething saturated from the ribsdown an old stonyword like ruin. Youre what roofI have frail thingyoure my argumentagainst the whole sky.Youre the fundamental differencebetween wet and dry.', 'You are the start of the weekor the end of it and accordingto The Beatles you creep inlike a nun. Youre the secondfull day the kids have beenaway with their father the secondfull day of an empty house.Sunday Ive missed you. Ive beensitting in the backyard with a glassof Pinot waiting for your arrival.Did you know the first Sweet sare turning red in the gardenbut the lettuce has growntoo bitter to eat. I am lookingup at the bluest sky I have ever seencerulean blue a heaven skyno one would believe I was under.You are my witness. No dayis promised. You are absolution.You are my unwritten todo listmy dishes in the sink my browniebreakfast my braless day.', 'Invisible fish swim this ghost ocean now described by waves of sand by waterworn rock. Soon the fish will learn to walk. Then humans will come ashore and paint dreams on the dying stone. Then later much later the ocean floor will be punctuated by Chevy trucks carrying the dreamers decendants who are going to the store.', 'Dont bother the earth spirit who lives here. She is working on a story. It is the oldest story in the world and it is delicate changing. If she sees you watching she will invite you in for coffee give you warm bread and you will be obligated to stay and listen. But this is no ordinary story. You will have to endure earthquakes lightning the deaths of all those you love the most blinding beauty. Its a story so compelling you may never want to leave this is how she traps you. See that stone finger over there? That is the only one who ever escaped.', 'Is anything central?Orchards flung out on the landUrban forests rustic plantations kneehigh hills?Are place names central?Elm Grove Adcock Corner Story Book Farm?As they concur with a rush at eye levelBeating themselves into eyes which have had enoughThank you no more thank you.And they come on like scenery mingled with darknessThe damp plains overgrown suburbsPlaces of known civic pride of civil obscurity. These are connected to my version of AmericaBut the juice is elsewhere.This morning as I walked out of your roomAfter breakfast crosshatched withBackward and forward glances backward into lightForward into unfamiliar lightWas it our doing and was itThe material the lumber of life or of livesWe were measuring counting?A mood soon to be forgottenIn crossed girders of light cool downtown shadowIn this morning that has seized us again? I know that I braid too much on my ownSnappedoff perceptions of things as they come to me.They are private and always will be.Where then are the private turns of eventDestined to bloom later like golden chimesReleased over a city from a highest tower?The quirky things that happen to me and I tell youAnd you know instantly what I mean?What remote orchard reached by winding roadsHides them? Where are these roots? It is the lumps and trialsThat tell us whether we shall be knownAnd whether our fate can be exemplary like a star.All the rest is waitingFor a letter that never arrivesDay after day the exasperationUntil finally you have ripped it open not knowing what it isThe two envelope halves lying on a plate.The message was wise and seeminglyDictated a long time ago but its time has stillNot arrived telling of danger and the mostly limitedSteps that can be taken against dangerNow and in the future in cool yardsIn quiet small houses in the countryOur country in fenced areas in cool shady streets.', 'Hour in which I consider hydrangea a salt or sand plant varietal the question of varietals the diet of every mother I know  pounds feels like  I have lost  I have lost yes a sense of my own possible beauty grown external I externalize beauty. Beauty occurs on the surface of plants the sun darkens the skin of my child he is so small he is beautiful I can see it is obvious and everything about him is beautiful. His hand swells from the bite spread? of some insects venom because he is small. He appears to feel nothing. He smashes his skull against the floor. He screams. I hold him in my lap on the kitchen floor in front of an open freezer pressing a pack of frozen clay against his forehead. He likes the cold. I see it is so obvious. Hydrangea. When I move when I walk pushing my childs stroller it is both walking and pushing or hauling sometimes also lifting it is having another body an adjunct body composed of errand and weight and tenderness and no small amount of power I imagine I can feel this small amount of weight this  pounds like  interfering with the twitch of every muscle in my body. As an object a mother is confusing a middleaged mother with little spare flesh I feel every inch of major muscle pulling against gravity and against the weight of my child now sleeping. This is the hour for thinking hydrangea. Let no man look at me. I stop to brush the drowsy childs little eye. His face. He barely considers his mother. I am all around him. Why should he consider what is all around him? Perhaps what is missing is a subtle power of differentiation. I am in therefore a time of mass apprehensions.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub(r\"[^A-Za-z.?! ]\", \"\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyMB11GOdmwm",
        "outputId": "d28a9240-f19c-4f5f-aa19-324b07643c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13854"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "with open('Terminator.txt', 'r') as f1:\n",
        "    text1 = f1.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "kNd5U0nMeOVk",
        "outputId": "c93fb0b2-827c-429b-c5d7-159f6a89840c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a29e1fe6-459a-47fc-8dcf-054cd36dde90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a29e1fe6-459a-47fc-8dcf-054cd36dde90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Terminator.txt to Terminator (3).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "with open('TERMINATOR 2 JUDGEMENT DAY.txt', 'r') as f2:\n",
        "    text2 = f2.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Mh7DkIG8rtFc",
        "outputId": "e67f1ef4-d813-41fe-e8e2-eb98eeac5214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-15e6fcd3-fbe2-4a47-8c83-33e533fb5493\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-15e6fcd3-fbe2-4a47-8c83-33e533fb5493\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TERMINATOR 2 JUDGEMENT DAY.txt to TERMINATOR 2 JUDGEMENT DAY.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "with open('Terminator Salvation.txt', 'r') as f3:\n",
        "    text3 = f3.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "v63vhzbMrs4y",
        "outputId": "1279cb82-d8bf-4eb3-c429-d391639ac3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af348e2a-f47b-4404-a182-00708eeedb84\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-af348e2a-f47b-4404-a182-00708eeedb84\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Terminator Salvation.txt to Terminator Salvation (1).txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text1[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2V9drwSpY5V",
        "outputId": "ece16c5d-70da-4cd6-cf88-0dc56c9381e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXT. SCHOOLYARD - NIGHT                                1\n",
            "\n",
            "        Silence.  Gradually the sound of distant traffic becomes\n",
            "        audible.  A LOW ANGLE bounded on one side by a chain-link\n",
            "        fence and on the other by the one-story public school build-\n",
            "        ings.  Spray-can hieroglyphics and distant streetlight sha-\n",
            "        dows.  This is a Los Angeles public school in a blue collar\n",
            "        neighborhood.\n",
            "\n",
            "        ANGLE BETWEEN SCHOOL BUILDINGS, where a trash dumpster looms\n",
            "        in a LOW ANGLE, part of the clutter behind the gymnasium.\n",
            "        A CAT enters FRAME.  CAMERA DOLLIES FORWARD, prowling with\n",
            "        him through the landscape of trash receptacles and shadows.\n",
            "\n",
            "        CLOSE ON CAT, which freezes, alert, sensing something just\n",
            "        beyond human perception.\n",
            "\n",
            "        A sourceless wind rises, and with it a keening WHINE.\n",
            "        Papers blow across the pavement.\n",
            "        The cat YOWLS and hides under the dumpster.\n",
            "        Windows rattle in their frames.\n",
            "        The WHIN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text2[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2VPAE3aplZG",
        "outputId": "ebe01f65-6977-4035-f9e8-43a9ffff91c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " EXT. CITY STREET - DAY\n",
            "\n",
            "        Downtown L.A.  Noon on a hot summer day.  On an EXTREME LONG LENS the\n",
            "        lunchtime crowd stacks up into a wall of humanity.  In SLOW MOTION\n",
            "        they move in herds among the glittering rows of cars jammed bumper to\n",
            "        bumper.  Heat ripples distort the torrent of faces.  The image is\n",
            "        surreal, dreamy... and like a dream it begins very slowly to\n",
            "\n",
            "                                                DISSOLVE TO:\n",
            "\n",
            "2       EXT. CITY RUINS - NIGHT\n",
            "\n",
            "        Same spot as the last shot, but now it is a landscape in Hell.  The\n",
            "        cars are stopped in rusted rows, still bumper to bumper.  The\n",
            "        skyline of buildings beyond has been shattered by some\n",
            "        unimaginable force like a row of kicked-down sandcastles.\n",
            "        Wind blows through the desolation, keening with the sound of ten\n",
            "        million dead souls.  It scurries the ashes into drifts, stark\n",
            "        white in the moonlight against the charred rubble.\n",
            "        A TITLE CARD FADES I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text3[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugt7Xtntrgl4",
        "outputId": "370295f4-0d29-4fa6-f9be-19eee0dbb911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INT.   DEATH ROW/CELL - DAWN\n",
            "          \n",
            "          START TIGHT ON MARCUS WRIGHT. He's an intense, powerful man,\n",
            "          20's-30's, his head shaven. Marcus stares INTO CAMERA with a\n",
            "          resigned expression. We hear the voice of a PRIEST:\n",
            "          \n",
            "                               PRIEST\n",
            "                     Yea, though I walk through the valley\n",
            "                     of the shadow of death, I will fear\n",
            "                     no evil: for thou art beside me; thy\n",
            "                     rod and thy staff they comfort me...\n",
            "          \n",
            "          CAMERA PULLS BACK, straight up. MARCUS lies in his cot,\n",
            "          staring at the ceiling. He's smoking a CIGARETTE. This\n",
            "          OVERHEAD ANGLE reveals a PRIEST with a BIBLE, in a folding\n",
            "          chair beside him. A CHESS SET, stacks of BOOKS, WRITING\n",
            "          MATERIALS in the cell. TWO GUARDS wait, shackles in hand.\n",
            "          \n",
            "          MARCUS has no interest in scripture. He blows a cloud of\n",
            "          SMOKE which drifts in the direction of the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tot_texts = text1 + text2 + text3\n",
        "\n",
        "print(tot_texts[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u5sSUkVrqCW",
        "outputId": "390259fd-f089-443b-e0d5-ce32f0463986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EXT. SCHOOLYARD - NIGHT                                1\n",
            "\n",
            "        Silence.  Gradually the sound of distant traffic becomes\n",
            "        audible.  A LOW ANGLE bounded on one side by a chain-link\n",
            "        fence and on the other by the one-story public school build-\n",
            "        ings.  Spray-can hieroglyphics and distant streetlight sha-\n",
            "        dows.  This is a Los Angeles public school in a blue collar\n",
            "        neighborhood.\n",
            "\n",
            "        ANGLE BETWEEN SCHOOL BUILDINGS, where a trash dumpster looms\n",
            "        in a LOW ANGLE, part of the clutter behind the gymnasium.\n",
            "        A CAT enters FRAME.  CAMERA DOLLIES FORWARD, prowling with\n",
            "        him through the landscape of trash receptacles and shadows.\n",
            "\n",
            "        CLOSE ON CAT, which freezes, alert, sensing something just\n",
            "        beyond human perception.\n",
            "\n",
            "        A sourceless wind rises, and with it a keening WHINE.\n",
            "        Papers blow across the pavement.\n",
            "        The cat YOWLS and hides under the dumpster.\n",
            "        Windows rattle in their frames.\n",
            "        The WHIN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tot_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWeTczKHte9w",
        "outputId": "6f40691a-a842-412c-e5e7-b5870103aca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "764106"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(tot_texts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1duxgRP6tiHD",
        "outputId": "d99389d2-77b0-4248-e7ec-e0148eec8c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_dc = '''\n",
        "I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
        "\n",
        "Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.\n",
        "\n",
        "But one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languished in the corners of American society and finds himself an exile in his own land. And so we've come here today to dramatize a shameful condition.\n",
        "\n",
        "In a sense we've come to our nation's capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir. This note was a promise that all men, yes, black men as well as white men, would be guaranteed the \"unalienable Rights\" of \"Life, Liberty and the pursuit of Happiness.\" It is obvious today that America has defaulted on this promissory note, insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked \"insufficient funds.\"\n",
        "\n",
        "But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so, we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice.\n",
        "\n",
        "We have also come to this hallowed spot to remind America of the fierce urgency of Now. This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice. Now is the time to lift our nation from the quicksands of racial injustice to the solid rock of brotherhood. Now is the time to make justice a reality for all of God's children.\n",
        "\n",
        "It would be fatal for the nation to overlook the urgency of the moment. This sweltering summer of the Negro's legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end, but a beginning. And those who hope that the Negro needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual. And there will be neither rest nor tranquility in America until the Negro is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.\n",
        "\n",
        "\n",
        "\n",
        "But there is something that I must say to my people, who stand on the warm threshold which leads into the palace of justice: In the process of gaining our rightful place, we must not be guilty of wrongful deeds. Let us not seek to satisfy our thirst for freedom by drinking from the cup of bitterness and hatred. We must forever conduct our struggle on the high plane of dignity and discipline. We must not allow our creative protest to degenerate into physical violence. Again and again, we must rise to the majestic heights of meeting physical force with soul force.\n",
        "\n",
        "The marvelous new militancy which has engulfed the Negro community must not lead us to a distrust of all white people, for many of our white brothers, as evidenced by their presence here today, have come to realize that their destiny is tied up with our destiny. And they have come to realize that their freedom is inextricably bound to our freedom.\n",
        "\n",
        "We cannot walk alone.\n",
        "\n",
        "And as we walk, we must make the pledge that we shall always march ahead.\n",
        "\n",
        "We cannot turn back.\n",
        "\n",
        "There are those who are asking the devotees of civil rights, \"When will you be satisfied?\" We can never be satisfied as long as the Negro is the victim of the unspeakable horrors of police brutality. We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities. **We cannot be satisfied as long as the negro's basic mobility is from a smaller ghetto to a larger one. We can never be satisfied as long as our children are stripped of their self-hood and robbed of their dignity by signs stating: \"For Whites Only.\"** We cannot be satisfied as long as a Negro in Mississippi cannot vote and a Negro in New York believes he has nothing for which to vote. No, no, we are not satisfied, and we will not be satisfied until \"justice rolls down like waters, and righteousness like a mighty stream.\"1\n",
        "\n",
        "\n",
        "\n",
        "I am not unmindful that some of you have come here out of great trials and tribulations. Some of you have come fresh from narrow jail cells. And some of you have come from areas where your quest -- quest for freedom left you battered by the storms of persecution and staggered by the winds of police brutality. You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive. Go back to Mississippi, go back to Alabama, go back to South Carolina, go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our northern cities, knowing that somehow this situation can and will be changed.\n",
        "\n",
        "Let us not wallow in the valley of despair, I say to you today, my friends.\n",
        "\n",
        "And so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American dream.\n",
        "\n",
        "I have a dream that one day this nation will rise up and live out the true meaning of its creed: \"We hold these truths to be self-evident, that all men are created equal.\"\n",
        "\n",
        "I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood.\n",
        "\n",
        "I have a dream that one day even the state of Mississippi, a state sweltering with the heat of injustice, sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.\n",
        "\n",
        "I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.\n",
        "\n",
        "I have a dream today!\n",
        "\n",
        "I have a dream that one day, down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of \"interposition\" and \"nullification\" -- one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.\n",
        "\n",
        "I have a dream today!\n",
        "\n",
        "I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight; \"and the glory of the Lord shall be revealed and all flesh shall see it together.\"2\n",
        "\n",
        "This is our hope, and this is the faith that I go back to the South with.\n",
        "\n",
        "With this faith, we will be able to hew out of the mountain of despair a stone of hope. With this faith, we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith, we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.\n",
        "\n",
        "And this will be the day -- this will be the day when all of God's children will be able to sing with new meaning:\n",
        "\n",
        "My country 'tis of thee, sweet land of liberty, of thee I sing. Land where my fathers died, land of the Pilgrim's pride,    From every mountainside, let freedom ring!\n",
        "\n",
        "And if America is to be a great nation, this must become true.\n",
        "\n",
        "And so let freedom ring from the prodigious hilltops of New Hampshire.\n",
        "\n",
        "Let freedom ring from the mighty mountains of New York.\n",
        "\n",
        "Let freedom ring from the heightening Alleghenies of Pennsylvania.\n",
        "\n",
        "Let freedom ring from the snow-capped Rockies of Colorado.\n",
        "\n",
        "Let freedom ring from the curvaceous slopes of California.\n",
        "\n",
        "But not only that:\n",
        "\n",
        "Let freedom ring from Stone Mountain of Georgia.\n",
        "\n",
        "Let freedom ring from Lookout Mountain of Tennessee.\n",
        "\n",
        "Let freedom ring from every hill and molehill of Mississippi.\n",
        "\n",
        "From every mountainside, let freedom ring.\n",
        "\n",
        "\n",
        "\n",
        "And when this happens, and when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual:\n",
        "\n",
        "Free at last! Free at last!\n",
        "\n",
        "Thank God Almighty, we are free at last!3\n",
        "'''.replace(\"\\n\", ' ')"
      ],
      "metadata": {
        "id": "f2XIwc4crey1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_dc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6QGH83fsJfk",
        "outputId": "d3ca7657-b103-42b8-b317-fb7598b841de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.  Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.  But one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languished in the corners of American society and finds himself an exile in his own land. And so we've come here today to dramatize a shameful condition.  In a sense we've come to our nation's capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir. This note was a promise that all men, yes, black men as well as white men, would be guaranteed the \"unalienable Rights\" of \"Life, Liberty and the pursuit of Happiness.\" It is obvious today that America has defaulted on this promissory note, insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked \"insufficient funds.\"  But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so, we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice.  We have also come to this hallowed spot to remind America of the fierce urgency of Now. This is no time to engage in the luxury of cooling off or to take the tranquilizing drug of gradualism. Now is the time to make real the promises of democracy. Now is the time to rise from the dark and desolate valley of segregation to the sunlit path of racial justice. Now is the time to lift our nation from the quicksands of racial injustice to the solid rock of brotherhood. Now is the time to make justice a reality for all of God's children.  It would be fatal for the nation to overlook the urgency of the moment. This sweltering summer of the Negro's legitimate discontent will not pass until there is an invigorating autumn of freedom and equality. Nineteen sixty-three is not an end, but a beginning. And those who hope that the Negro needed to blow off steam and will now be content will have a rude awakening if the nation returns to business as usual. And there will be neither rest nor tranquility in America until the Negro is granted his citizenship rights. The whirlwinds of revolt will continue to shake the foundations of our nation until the bright day of justice emerges.    But there is something that I must say to my people, who stand on the warm threshold which leads into the palace of justice: In the process of gaining our rightful place, we must not be guilty of wrongful deeds. Let us not seek to satisfy our thirst for freedom by drinking from the cup of bitterness and hatred. We must forever conduct our struggle on the high plane of dignity and discipline. We must not allow our creative protest to degenerate into physical violence. Again and again, we must rise to the majestic heights of meeting physical force with soul force.  The marvelous new militancy which has engulfed the Negro community must not lead us to a distrust of all white people, for many of our white brothers, as evidenced by their presence here today, have come to realize that their destiny is tied up with our destiny. And they have come to realize that their freedom is inextricably bound to our freedom.  We cannot walk alone.  And as we walk, we must make the pledge that we shall always march ahead.  We cannot turn back.  There are those who are asking the devotees of civil rights, \"When will you be satisfied?\" We can never be satisfied as long as the Negro is the victim of the unspeakable horrors of police brutality. We can never be satisfied as long as our bodies, heavy with the fatigue of travel, cannot gain lodging in the motels of the highways and the hotels of the cities. **We cannot be satisfied as long as the negro's basic mobility is from a smaller ghetto to a larger one. We can never be satisfied as long as our children are stripped of their self-hood and robbed of their dignity by signs stating: \"For Whites Only.\"** We cannot be satisfied as long as a Negro in Mississippi cannot vote and a Negro in New York believes he has nothing for which to vote. No, no, we are not satisfied, and we will not be satisfied until \"justice rolls down like waters, and righteousness like a mighty stream.\"1    I am not unmindful that some of you have come here out of great trials and tribulations. Some of you have come fresh from narrow jail cells. And some of you have come from areas where your quest -- quest for freedom left you battered by the storms of persecution and staggered by the winds of police brutality. You have been the veterans of creative suffering. Continue to work with the faith that unearned suffering is redemptive. Go back to Mississippi, go back to Alabama, go back to South Carolina, go back to Georgia, go back to Louisiana, go back to the slums and ghettos of our northern cities, knowing that somehow this situation can and will be changed.  Let us not wallow in the valley of despair, I say to you today, my friends.  And so even though we face the difficulties of today and tomorrow, I still have a dream. It is a dream deeply rooted in the American dream.  I have a dream that one day this nation will rise up and live out the true meaning of its creed: \"We hold these truths to be self-evident, that all men are created equal.\"  I have a dream that one day on the red hills of Georgia, the sons of former slaves and the sons of former slave owners will be able to sit down together at the table of brotherhood.  I have a dream that one day even the state of Mississippi, a state sweltering with the heat of injustice, sweltering with the heat of oppression, will be transformed into an oasis of freedom and justice.  I have a dream that my four little children will one day live in a nation where they will not be judged by the color of their skin but by the content of their character.  I have a dream today!  I have a dream that one day, down in Alabama, with its vicious racists, with its governor having his lips dripping with the words of \"interposition\" and \"nullification\" -- one day right there in Alabama little black boys and black girls will be able to join hands with little white boys and white girls as sisters and brothers.  I have a dream today!  I have a dream that one day every valley shall be exalted, and every hill and mountain shall be made low, the rough places will be made plain, and the crooked places will be made straight; \"and the glory of the Lord shall be revealed and all flesh shall see it together.\"2  This is our hope, and this is the faith that I go back to the South with.  With this faith, we will be able to hew out of the mountain of despair a stone of hope. With this faith, we will be able to transform the jangling discords of our nation into a beautiful symphony of brotherhood. With this faith, we will be able to work together, to pray together, to struggle together, to go to jail together, to stand up for freedom together, knowing that we will be free one day.  And this will be the day -- this will be the day when all of God's children will be able to sing with new meaning:  My country 'tis of thee, sweet land of liberty, of thee I sing. Land where my fathers died, land of the Pilgrim's pride,    From every mountainside, let freedom ring!  And if America is to be a great nation, this must become true.  And so let freedom ring from the prodigious hilltops of New Hampshire.  Let freedom ring from the mighty mountains of New York.  Let freedom ring from the heightening Alleghenies of Pennsylvania.  Let freedom ring from the snow-capped Rockies of Colorado.  Let freedom ring from the curvaceous slopes of California.  But not only that:  Let freedom ring from Stone Mountain of Georgia.  Let freedom ring from Lookout Mountain of Tennessee.  Let freedom ring from every hill and molehill of Mississippi.  From every mountainside, let freedom ring.    And when this happens, and when we allow freedom ring, when we let it ring from every village and every hamlet, from every state and every city, we will be able to speed up that day when all of God's children, black men and white men, Jews and Gentiles, Protestants and Catholics, will be able to join hands and sing in the words of the old Negro spiritual:  Free at last! Free at last!  Thank God Almighty, we are free at last!3 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "id": "KkSNO2KWsxaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2588dc4-976a-46bf-ab52-66cb252b9b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the shake heightening honoring slopes,I heavy make horrors marked end even island great asking cup capital veterans,I your signs blow oppression of your riches of smaller ghettos!I Go asking,I America cannot white join shake shall of negro slums meeting.I And'with given'a can sweltering end heightening your ago discrimination the ahead northern oasis himself whirlwinds poverty the rolls of beginning creed righteousness of this be brutality.I I have all free molehill slaves shall funds has crippled,I Negro dignity I\"for steam steam your ghetto shall of little marked discrimination!I We of'we came character a discipline,I go hotels men words funds remind,I And blow signs sit wrongful people creed rooted in score of invigorating the stone,I cannot a,I and a emerges pursuit,I I a island returns of village color hope shameful transformed security spiritual,I larger insufficient,I cooling to the who promise of funds insofar color to the an freedom mountain drinking end promises a crooked in Hampshire \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_dc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NTVrn-71HM3",
        "outputId": "61edbe28-f1b5-4a1a-bd4a-a3991a2994bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9180"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "5000 * 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1z6PzF8SF1a",
        "outputId": "43502a4e-52a0-4798-9d9e-8df82ad239c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300000"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "300000 / 9180"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4EGiC_MSfvr",
        "outputId": "8fbdd2bd-59e9-42d9-8b25-226b2bc20dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32.6797385620915"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "9000 * 5000 / 1363424"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYtvcQZXSi7B",
        "outputId": "238e8ec7-87dd-4c4c-bf0d-e367c3b05eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.0051400004694"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "50 * 5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF0ImYJIUE89",
        "outputId": "aa542012-1718-467f-82fd-85dd29bf92e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "100000 / 15000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Q7j5y5QXS1Q",
        "outputId": "0c0fa23b-000f-4dfb-f1d8-711036a6f3ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okJtjknwXjbn",
        "outputId": "a63537ed-754f-4496-df1f-d52c87e2e43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnP70lA3LyY0",
        "outputId": "136231da-9e1d-464c-d911-67b79699c120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWIerrDDigZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}